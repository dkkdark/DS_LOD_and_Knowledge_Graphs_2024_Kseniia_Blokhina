{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api-beta.openaire.eu/graph/researchProducts\"\n",
    "params = {\n",
    "    \"page\": 10,\n",
    "    \"pageSize\": 100,\n",
    "    \"sortBy\": \"relevance DESC\",\n",
    "    \"type\": \"publication\"\n",
    "}\n",
    "headers = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(f\"Failed {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /opt/homebrew/lib/python3.11/site-packages (5.27.0)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/lib/python3.11/site-packages (from neo4j) (2024.2)\n"
     ]
    }
   ],
   "source": [
    "!python3.11 -m pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files generated: main.csv, authors.csv, keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def flatten_main(record):\n",
    "    return {\n",
    "        'id': record.get('id', ''),\n",
    "        'title': record.get('mainTitle', ''),\n",
    "        'description': ' '.join(record.get('description', [])),\n",
    "        'type': record.get('type', ''),\n",
    "        'language': record.get('language', {}).get('label', ''),\n",
    "        'publicationDate': record.get('publicationDate', ''),\n",
    "        'publisher': record.get('publisher', '')\n",
    "    }\n",
    "\n",
    "def flatten_authors(record):\n",
    "    authors = []\n",
    "    for author in record.get('author', []):\n",
    "        authors.append({\n",
    "            'id': record.get('id', ''),\n",
    "            'fullName': author.get('fullName', ''),\n",
    "            'rank': author.get('rank', '')\n",
    "        })\n",
    "    return authors\n",
    "\n",
    "def flatten_keywords(record):\n",
    "    keywords = []\n",
    "    for subject in record.get('subjects', []):\n",
    "        keywords.append({\n",
    "            'id': record['id'],\n",
    "            'keyword': subject['subject']['value']\n",
    "        })\n",
    "    return keywords\n",
    "\n",
    "main_records = []\n",
    "authors_records = []\n",
    "keywords_records = []\n",
    "\n",
    "for result in data['results']:\n",
    "    main_records.append(flatten_main(result))\n",
    "    authors_records.extend(flatten_authors(result))\n",
    "    keywords_records.extend(flatten_keywords(result))\n",
    "\n",
    "def write_csv(filename, fieldnames, records):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "\n",
    "write_csv('main.csv', ['id', 'title', 'description', 'type', 'language', 'publicationDate', 'publisher'], main_records)\n",
    "write_csv('authors.csv', ['id', 'fullName', 'rank'], authors_records)\n",
    "write_csv('keywords.csv', ['id', 'keyword'], keywords_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fullName</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi_________::4b7f84c788e28f843e3ac21a9b63c562</td>\n",
       "      <td>T. J. HODGKINSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi_________::4b7f84c788e28f843e3ac21a9b63c562</td>\n",
       "      <td>L. R. KELLAND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi_________::4b7f84c788e28f843e3ac21a9b63c562</td>\n",
       "      <td>M. SHIPMAN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doi_________::4b7f84c788e28f843e3ac21a9b63c562</td>\n",
       "      <td>J. VILE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doi_________::4cfb3f1d8dd3382051c28e771df44af2</td>\n",
       "      <td>Yasuhiro Tezuka</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>doi_________::4cfb3f1d8dd3382051c28e771df44af2</td>\n",
       "      <td>Mohammad S. Ali</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id          fullName  rank\n",
       "0  doi_________::4b7f84c788e28f843e3ac21a9b63c562  T. J. HODGKINSON     1\n",
       "1  doi_________::4b7f84c788e28f843e3ac21a9b63c562     L. R. KELLAND     2\n",
       "2  doi_________::4b7f84c788e28f843e3ac21a9b63c562        M. SHIPMAN     3\n",
       "3  doi_________::4b7f84c788e28f843e3ac21a9b63c562           J. VILE     4\n",
       "4  doi_________::4cfb3f1d8dd3382051c28e771df44af2   Yasuhiro Tezuka     1\n",
       "5  doi_________::4cfb3f1d8dd3382051c28e771df44af2   Mohammad S. Ali     2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/kseniablokhina/Desktop/LOD-OperAire-KG/authors.csv\")\n",
    "df.dropna()\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to clean keywords because they contain a lot of noise information\n",
    "import re\n",
    "df = pd.read_csv(\"/Users/kseniablokhina/Desktop/LOD-OperAire-KG/keywords.csv\")\n",
    "\n",
    "def clean_keyword(keyword):\n",
    "    keyword = re.sub(r\"\\[.*?\\]\", \"\", keyword)\n",
    "    keyword = re.sub(r\"\\b\\d+\\b\", \"\", keyword)\n",
    "    keyword = re.sub(r\"\\s+\", \" \", keyword).strip()\n",
    "    return keyword\n",
    "\n",
    "df[\"keyword\"] = df[\"keyword\"].apply(clean_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df.replace('', np.nan).dropna()\n",
    "df = df.replace('.', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "\n",
    "uri = \"\" \n",
    "username = \"neo4j\"\n",
    "password = \"\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def upload_data_from_csv(file_path, query):\n",
    "    with driver.session() as session:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                session.run(query, row)\n",
    "\n",
    "query_main = \"\"\"\n",
    "MERGE (r:Record {id: $id})\n",
    "SET r.title = $title, \n",
    "    r.description = $description, \n",
    "    r.type = $type, \n",
    "    r.language = $language, \n",
    "    r.publicationDate = $publicationDate, \n",
    "    r.publisher = $publisher\n",
    "\"\"\"\n",
    "\n",
    "query_authors = \"\"\"\n",
    "MERGE (a:Author {fullName: $fullName})\n",
    "SET a.rank = $rank\n",
    "WITH a\n",
    "MATCH (r:Record {id: $id})\n",
    "MERGE (r)-[:HAS_AUTHOR]->(a)\n",
    "\"\"\"\n",
    "\n",
    "query_keywords = \"\"\"\n",
    "MERGE (k:Keyword {keyword: $keyword})\n",
    "WITH k\n",
    "MATCH (r:Record {id: $id})\n",
    "MERGE (r)-[:HAS_KEYWORD]->(k)\n",
    "\"\"\"\n",
    "\n",
    "upload_data_from_csv('main.csv', query_main)\n",
    "upload_data_from_csv('authors.csv', query_authors)\n",
    "upload_data_from_csv('keywords.csv', query_keywords)\n",
    "\n",
    "driver.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
